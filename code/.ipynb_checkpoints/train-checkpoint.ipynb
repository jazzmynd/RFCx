{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LambdaCallback\n",
    "\n",
    "from datagen import get_files_and_labels, scalespec, preprocess, DataGenerator\n",
    "from learningrate import warmup_cosine_decay, WarmUpCosineDecayScheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = './model' # path to output model\n",
    "data_dir = '/home/ubuntu/data/bio/puerto-rico/specs/' # path to directory with spectrogram data\n",
    "# expected format:\n",
    "#     data_dir/\n",
    "#         p/\n",
    "#             <class_1>/\n",
    "#                 <audio_filename>.wav\n",
    "#                 ...\n",
    "#             <class_2>/\n",
    "#                 <audio_filename>.wav\n",
    "#                 ...\n",
    "#         n/\n",
    "#             <class_1>/\n",
    "#                 <audio_filename>.wav\n",
    "#                 ...\n",
    "#             <class_2>/\n",
    "#                 <audio_filename>.wav\n",
    "#                 ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify list of target classes\n",
    "class_list = os.listdir(data_dir+'/p/')\n",
    "num_classes = len(class_list)\n",
    "num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get training file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.8\n",
    "\n",
    "# generate positive train file paths\n",
    "files_train_p, files_val_p, labels = get_files_and_labels(data_dir+'p/',\n",
    "                                                          train_split=train_split,\n",
    "                                                          random_state=42,\n",
    "                                                          classes=class_list)\n",
    "\n",
    "# generate negative train file paths\n",
    "files_train_n, files_val_n, labels_n = get_files_and_labels(data_dir+'n/',\n",
    "                                                            train_split=train_split,\n",
    "                                                            random_state=42,\n",
    "                                                            classes=class_list) \n",
    "\n",
    "labels_rev = dict((v,k) for (k,v) in labels.items())\n",
    "files_train_n = [i for i in files_train_n if i.split('/')[-2] in list(labels.keys())]\n",
    "files_train = files_train_p+files_train_n\n",
    "files_val = files_val_p+files_val_n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_dim = [224, 224] # desired shape of generated images\n",
    "augment = 1 # whether to apply data augmentation\n",
    "batch_size = 32\n",
    "\n",
    "# train data generator\n",
    "train_generator = DataGenerator(files_train,\n",
    "                                labels,\n",
    "                                resize_dim=resize_dim,\n",
    "                                batch_size=batch_size,\n",
    "                                augment=augment)\n",
    "\n",
    "# validation data generator\n",
    "val_generator = DataGenerator(files_val,\n",
    "                              labels,\n",
    "                              resize_dim=resize_dim,\n",
    "                              batch_size=batch_size,\n",
    "                              augment=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = MobileNetV2(weights='imagenet', \n",
    "                   include_top=False, \n",
    "                   input_shape=[224, 224, 3])\n",
    "\n",
    "for layer in conv.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv)\n",
    "model.add(layers.AveragePooling2D((7, 7)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# note: this loss can be used to avoid assumptions about unlabeled classes\n",
    "# def masked_loss(y_true, y_pred):\n",
    "#     return K.mean(K.mean(K.binary_crossentropy(tf.where(tf.math.is_nan(y_true), tf.zeros_like(y_true), y_true),\n",
    "#                                                tf.multiply(y_pred, tf.cast(tf.logical_not(tf.math.is_nan(y_true)), tf.float32))), axis=-1))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizer)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model architecture\n",
    "model_json = model.to_json()\n",
    "with open(model_out+'.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "with open(model_out+'_classes.json', 'w') as f:\n",
    "    json.dump(labels_rev, f)\n",
    "print('Saved model architecture')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parameters specify the shape of a learning rate curve that has warmup and cosine decay. See learningrate.py for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "warmup_lr = 1e-5\n",
    "warmup_epochs = int(epochs*0.1)\n",
    "patience = epochs\n",
    "steps_per_epoch = len(train_generator)\n",
    "base_lr = 0.0015\n",
    "hold_base_rate_steps = int(epochs*0.125*steps_per_epoch)\n",
    "\n",
    "total_steps = int(epochs * steps_per_epoch)\n",
    "warmup_steps = int(warmup_epochs * steps_per_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning rate\n",
    "rng = [i for i in range(0, int(epochs * steps_per_epoch), 1000)]\n",
    "lr = [warmup_cosine_decay(x, \n",
    "                          base_lr, \n",
    "                          int(epochs*steps_per_epoch), \n",
    "                          warmup_lr, \n",
    "                          int(warmup_epochs * steps_per_epoch),\n",
    "                          hold_base_rate_steps) for x in rng]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "plt.plot([i/steps_per_epoch for i in rng], lr)\n",
    "plt.grid()\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Epoch');\n",
    "plt.show();\n",
    "del lr, rng\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best model weights based on validation loss\n",
    "val_chkpt = ModelCheckpoint(filepath=model_out+'_best_val.h5',\n",
    "                            save_weights_only=True,\n",
    "                            monitor='val_loss',\n",
    "                            mode='min',\n",
    "                            save_best_only=True,\n",
    "                            verbose=1)\n",
    "\n",
    "# also save the model weights every 20 epochs\n",
    "reg_chkpt = ModelCheckpoint(filepath=model_out+'{epoch:04d}.h5',\n",
    "                            save_weights_only=True,\n",
    "                            save_freq=int(steps_per_epoch*20))\n",
    "\n",
    "# apply a learning rate schedule\n",
    "cosine_warm_up_lr = WarmUpCosineDecayScheduler(learning_rate_base= base_lr,\n",
    "                                               total_steps= total_steps,\n",
    "                                               warmup_learning_rate= warmup_lr,\n",
    "                                               warmup_steps= warmup_steps,\n",
    "                                               hold_base_rate_steps=hold_base_rate_steps)\n",
    "\n",
    "callbacks_list = [val_chkpt, reg_chkpt, cosine_warm_up_lr]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(train_generator,\n",
    "                          steps_per_epoch = len(train_generator),\n",
    "                          validation_data = val_generator,\n",
    "                          epochs = epochs,\n",
    "                          verbose = 1,\n",
    "                          callbacks=callbacks_list)\n",
    "np.save(model_out+'_history.npy', model_history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m80"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
